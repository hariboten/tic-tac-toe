# エージェント対戦表 可視化計画

## 背景
- エージェントの強さを直感的に比較できる導線が不足している。
- 既存の「比較」タブは学習量（累計エピソード・状態数）のみで、実戦性能の差が見えにくい。

## 目的
- エージェント同士を総当たりで対戦させ、勝率を表形式で可視化する。
- 勝率表示により、学習済みQ学習プロファイルの強さ比較を可能にする。

## 対象範囲
- `エージェント > 比較` ワークスペースに「対戦表（勝率）」を追加。
- シミュレーション対象:
  - ランダム
  - モンテカルロ
  - ミニマックス
  - Q学習（プロファイル A/B/C）

## 仕様
1. 対戦数（1カードあたり）を入力可能にする（最小1、既定は40程度）。
2. 「対戦表を更新」ボタンで全カードを再計算する。
3. 先手後手の偏りを減らすため、1カード内でX/O担当を半分ずつ入れ替える。
4. 表示内容
   - 行: 対戦元エージェント
   - 列: 対戦先エージェント
   - セル: 行エージェント視点の勝率（%）
   - 対角セル: `—`
5. 補助情報
   - 勝率算出中ステータス
   - 各エージェントの平均勝率（行平均）

## 実装方針
- `AppComponent` に対戦表用の状態を追加。
- 内部で `TicTacToeEngine` を使って1ゲームずつ高速にシミュレーション。
- エージェントごとの `pickMove` 呼び出しは既存実装（Random/MonteCarlo/Minimax/QLearning）を活用。
- UIは既存 compare セクションにカード追加し、テーブルを描画。

## テスト方針
- compareワークスペースで対戦表の行列ヘッダが表示されること。
- 「対戦表を更新」で結果セル（%）が少なくとも1つ表示されること。
- 実行中フラグにより、ボタンdisable制御が効くこと。
